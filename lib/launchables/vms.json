[
  {
    "slug": "ubuntu-24-vm",
    "name": "Ubuntu VM",
    "description": "Lightweight Ubuntu VM with full SSH access, ideal for configuring your own stack from scratch.",
    "repository": "https://hub.docker.com/_/ubuntu",
    "category": "OS VMs"
  },
  {
    "slug": "alpine",
    "name": "Alpine VM",
    "description": "Lightweight Alpine Linux VM with full SSH access, ideal for minimal resource usage and custom configurations.",
    "repository": "https://hub.docker.com/_/alpine",
    "category": "OS VMs"
  },
  {
    "slug": "debian",
    "name": "Debian VM",
    "description": "Stable Debian Linux VM with full SSH access, perfect for production environments and enterprise applications.",
    "repository": "https://hub.docker.com/_/debian",
    "category": "OS VMs"
  },
  {
    "slug": "pytorch-conda-cuda",
    "name": "PyTorch Conda CUDA",
    "description": "PyTorch environment with Conda package manager and CUDA support for GPU-accelerated deep learning development.",
    "repository": "https://hub.docker.com/r/pytorch/conda-cuda",
    "category": "VMs"
  },
  {
    "slug": "nvidia-cuda",
    "name": "NVIDIA CUDA",
    "description": "NVIDIA CUDA toolkit environment for GPU computing, parallel processing, and high-performance computing applications.",
    "repository": "https://hub.docker.com/r/nvidia/cuda",
    "category": "VMs"
  },
  {
    "slug": "nvidia-tensorrt-llm",
    "name": "NVIDIA TensorRT-LLM",
    "description": "Optimized environment for large language model inference with NVIDIA TensorRT-LLM for high-performance AI serving.",
    "repository": "https://hub.docker.com/r/nvidia/tensorrt-llm",
    "category": "VMs"
  },
  {
    "slug": "tensorflow",
    "name": "TensorFlow",
    "description": "Official TensorFlow environment for machine learning model development, training, and deployment.",
    "repository": "https://hub.docker.com/r/tensorflow/tensorflow",
    "category": "VMs"
  }
]
